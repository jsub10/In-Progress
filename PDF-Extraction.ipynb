{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Text, Tables, and Images from a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits\n",
    "- http://www.unixuser.org/~euske/python/pdfminer/programming.html\n",
    "- https://github.com/dpapathanasiou/pdfminer-layout-scanner/blob/master/layout_scanner.py\n",
    "\n",
    "**Requires** PDFMiner (https://github.com/euske/pdfminer)\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Due to a problem in the PDFMiner library, once PDFMiner is installed, you have to set it back to a previous version using:\n",
    "\n",
    "`pip install --upgrade --ignore-installed slate==0.3 pdfminer==20131113`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Text from a PDF Using PDFMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import sys\n",
    "import os\n",
    "from binascii import b2a_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PDFMiner imports\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument, PDFNoOutlines\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine, LTFigure, LTImage, LTChar\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "# For conversion to html\n",
    "from pdfminer.converter import HTMLConverter\n",
    "from pdfminer.converter import TextConverter\n",
    "from cStringIO import StringIO\n",
    "import re\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory for the extracted image files\n",
    "image_dir = os.getcwd() + '/PDF-Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set parameters for analysis.\n",
    "laparams = LAParams()\n",
    "# Create a PDF resource manager object that stores shared resources.\n",
    "rsrcmgr = PDFResourceManager()\n",
    "# Create a PDF page aggregator object.\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "for page in PDFPage.create_pages(document):\n",
    "    interpreter.process_page(page)\n",
    "    # receive the LTPage object for the page.\n",
    "    layout = device.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See http://denis.papathanasiou.org/posts/2010.08.04.post.html for code and explanation\n",
    "\n",
    "# Highest level utility function -- pass in other functions as the second argument\n",
    "def with_pdf (pdf_doc, fn, pdf_pwd, *args):\n",
    "    \"\"\"Open the pdf document, and apply the function, returning the results\"\"\"\n",
    "    result = None\n",
    "    try:\n",
    "        # open the pdf file\n",
    "        fp = open(pdf_doc, 'rb')\n",
    "        # create a parser object associated with the file object\n",
    "        parser = PDFParser(fp)\n",
    "        # create a PDFDocument object that stores the document structure\n",
    "        doc = PDFDocument(parser)\n",
    "        # connect the parser and document objects\n",
    "        parser.set_document(doc)\n",
    "        # supply the password for initialization\n",
    "        doc.initialize(pdf_pwd)\n",
    "\n",
    "        if doc.is_extractable:\n",
    "            # apply the function and return the result\n",
    "            result = fn(doc, *args)\n",
    "\n",
    "        # close the pdf file\n",
    "        fp.close()\n",
    "    except IOError:\n",
    "        # the file doesn't exist or similar problem\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "\n",
    "### \n",
    "### Table of Contents\n",
    "### \n",
    "\n",
    "def _parse_toc (doc):\n",
    "    \"\"\"With an open PDFDocument object, get the table of contents (toc) data\n",
    "    [this is a higher-order function to be passed to with_pdf()]\"\"\"\n",
    "    toc = []\n",
    "    try:\n",
    "        outlines = doc.get_outlines()\n",
    "        for (level,title,dest,a,se) in outlines:\n",
    "            toc.append( (level, title) )\n",
    "    except PDFNoOutlines:\n",
    "        pass\n",
    "    return toc\n",
    "\n",
    "def get_toc (pdf_doc, pdf_pwd=''):\n",
    "    \"\"\"Return the table of contents (toc), if any, for this pdf file\"\"\"\n",
    "    return with_pdf(pdf_doc, _parse_toc, pdf_pwd)\n",
    "\n",
    "###\n",
    "### Extracting Images\n",
    "###\n",
    "\n",
    "def write_file (folder, filename, filedata, flags='w'):\n",
    "    \"\"\"Write the file data to the folder and filename combination\n",
    "    (flags: 'w' for write text, 'wb' for write binary, use 'a' instead of 'w' for append)\"\"\"\n",
    "    result = False\n",
    "    if os.path.isdir(folder):\n",
    "        try:\n",
    "            file_obj = open(os.path.join(folder, filename), flags)\n",
    "            file_obj.write(filedata)\n",
    "            file_obj.close()\n",
    "            result = True\n",
    "        except IOError:\n",
    "            pass\n",
    "    return result\n",
    "\n",
    "def determine_image_type (stream_first_4_bytes):\n",
    "    \"\"\"Find out the image file type based on the magic number comparison of the first 4 (or 2) bytes\"\"\"\n",
    "    file_type = None\n",
    "    bytes_as_hex = b2a_hex(stream_first_4_bytes)\n",
    "    if bytes_as_hex.startswith('ffd8'):\n",
    "        file_type = '.jpeg'\n",
    "    elif bytes_as_hex == '89504e47':\n",
    "        file_type = '.png'\n",
    "    elif bytes_as_hex == '47494638':\n",
    "        file_type = '.gif'\n",
    "    elif bytes_as_hex.startswith('424d'):\n",
    "        file_type = '.bmp'\n",
    "    return file_type\n",
    "\n",
    "def save_image (lt_image, page_number, images_folder):\n",
    "    \"\"\"Try to save the image data from this LTImage object, and return the file name, if successful\"\"\"\n",
    "    result = None\n",
    "    if lt_image.stream:\n",
    "        file_stream = lt_image.stream.get_rawdata()\n",
    "        if file_stream:\n",
    "            file_ext = determine_image_type(file_stream[0:4])\n",
    "            if file_ext:\n",
    "                file_name = ''.join([str(page_number), '_', lt_image.name, file_ext])\n",
    "                if write_file(images_folder, file_name, file_stream, flags='wb'):\n",
    "                    result = file_name\n",
    "    return result\n",
    "\n",
    "\n",
    "###\n",
    "### Extracting Text\n",
    "###\n",
    "\n",
    "def to_bytestring (s, enc='utf-8'):\n",
    "    \"\"\"Convert the given unicode string to a bytestring, using the standard encoding,\n",
    "    unless it's already a bytestring\"\"\"\n",
    "    if s:\n",
    "        if isinstance(s, str):\n",
    "            return s\n",
    "        else:\n",
    "            return s.encode(enc)\n",
    "\n",
    "def update_page_text_hash (h, lt_obj, pct=0.2):\n",
    "    \"\"\"Use the bbox x0,x1 values within pct% to produce lists of associated text within the hash\"\"\"\n",
    "\n",
    "    x0 = lt_obj.bbox[0]\n",
    "    x1 = lt_obj.bbox[2]\n",
    "\n",
    "    key_found = False\n",
    "    for k, v in h.items():\n",
    "        hash_x0 = k[0]\n",
    "        if x0 >= (hash_x0 * (1.0-pct)) and (hash_x0 * (1.0+pct)) >= x0:\n",
    "            hash_x1 = k[1]\n",
    "            if x1 >= (hash_x1 * (1.0-pct)) and (hash_x1 * (1.0+pct)) >= x1:\n",
    "                # the text inside this LT* object was positioned at the same\n",
    "                # width as a prior series of text, so it belongs together\n",
    "                key_found = True\n",
    "                v.append(to_bytestring(lt_obj.get_text()))\n",
    "                h[k] = v\n",
    "    if not key_found:\n",
    "        # the text, based on width, is a new series,\n",
    "        # so it gets its own series (entry in the hash)\n",
    "        h[(x0,x1)] = [to_bytestring(lt_obj.get_text())]\n",
    "\n",
    "    return h\n",
    "\n",
    "def parse_lt_objs (lt_objs, page_number, images_folder, text=[]):\n",
    "    \"\"\"Iterate through the list of LT* objects and capture the text or image data contained in each\"\"\"\n",
    "    text_content = [] \n",
    "\n",
    "    page_text = {} # k=(x0, x1) of the bbox, v=list of text strings within that bbox width (physical column)\n",
    "    for lt_obj in lt_objs:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            # text, so arrange is logically based on its column width\n",
    "            page_text = update_page_text_hash(page_text, lt_obj)\n",
    "        elif isinstance(lt_obj, LTImage):\n",
    "            # an image, so save it to the designated folder, and note its place in the text \n",
    "            saved_file = save_image(lt_obj, page_number, images_folder)\n",
    "            if saved_file:\n",
    "                # use html style <img /> tag to mark the position of the image within the text\n",
    "                text_content.append('<img src=\"'+os.path.join(images_folder, saved_file)+'\" />')\n",
    "            else:\n",
    "                print >> sys.stderr, \"error saving image on page\", page_number, lt_obj.__repr__\n",
    "        elif isinstance(lt_obj, LTFigure):\n",
    "            # LTFigure objects are containers for other LT* objects, so recurse through the children\n",
    "            text_content.append(parse_lt_objs(lt_obj, page_number, images_folder, text_content))\n",
    "\n",
    "    for k, v in sorted([(key,value) for (key,value) in page_text.items()]):\n",
    "        # sort the page_text hash by the keys (x0,x1 values of the bbox),\n",
    "        # which produces a top-down, left-to-right sequence of related columns\n",
    "        text_content.append(''.join(v))\n",
    "\n",
    "    return '\\n'.join(text_content)\n",
    "\n",
    "\n",
    "###\n",
    "### Processing Pages\n",
    "###\n",
    "\n",
    "def _parse_pages (doc, images_folder):\n",
    "    \"\"\"With an open PDFDocument object, get the pages and parse each one\n",
    "    [this is a higher-order function to be passed to with_pdf()]\"\"\"\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    laparams = LAParams()\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "    text_content = []\n",
    "    for i, page in enumerate(PDFPage.create_pages(doc)):\n",
    "        interpreter.process_page(page)\n",
    "        # receive the LTPage object for this page\n",
    "        layout = device.get_result()\n",
    "        # layout is an LTPage object which may contain child objects like LTTextBox, LTFigure, LTImage, etc.\n",
    "        text_content.append(parse_lt_objs(layout, (i+1), images_folder))\n",
    "\n",
    "    return text_content\n",
    "\n",
    "def get_pages (pdf_doc, pdf_pwd='', images_folder='/tmp'):\n",
    "    \"\"\"Process each of the pages in this pdf file and return a list of strings representing the text found in each page\"\"\"\n",
    "    return with_pdf(pdf_doc, _parse_pages, pdf_pwd, *tuple([images_folder]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for HTML extraction\n",
    "# From https://gist.github.com/zross/10298077\n",
    "def convert_pdf_to_html(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = HTMLConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = file(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0 #is for all\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    str = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    \n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./PDFs/4612801 Supplier Spec.pdf', './PDFs/Aquamin Spec Sheet.pdf', './PDFs/Banko-and-Brill-Scaling-to-Large-Corpora.pdf', './PDFs/Booz Allen Field Guide to Data Science 2015.pdf', './PDFs/Building Machines that Think Like Humans - Survey of AI.pdf', './PDFs/Cognitive Reflection Test - Shane Frederick.pdf', './PDFs/data.pdf', './PDFs/OG GUAR 3500 F-D [PDS].pdf', './PDFs/the-new-artificial-intelligence-market.pdf', './PDFs/Unskilled and Unaware - Kruger and Dunning.pdf']\n"
     ]
    }
   ],
   "source": [
    "# PDF files live in the ./PDFs directory\n",
    "# list the files in that directory\n",
    "import glob\n",
    "print(glob.glob('./PDFs/*.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the first file from the list\n",
    "file_path = os.getcwd() + '/PDFs/'\n",
    "file_name1 = file_path + 'OG GUAR 3500 F-D [PDS].pdf'\n",
    "file_name2 = file_path + '4612801 Supplier Spec.pdf'\n",
    "file_name3 = file_path + 'Aquamin Spec Sheet.pdf'\n",
    "file_name4 = file_path + 'TruMarine Spec Sheet.pdf'\n",
    "file_name5 = file_path + 'Spec Sheet (4612800).pdf'\n",
    "file_name6 = file_path + 'B6_Pyridoxine Hydrochloride_Specs and Testing.pdf'\n",
    "file_name7 = file_path + 'B3_Niacinamide_Specs and Testing.pdf'\n",
    "\n",
    "\n",
    "file_name8 = file_path + 'Cognitive Reflection Test - Shane Frederick.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PDFMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the table of contents of the selected PDF\n",
    "get_toc(file_name5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error saving image on page 1 <bound method LTImage.__repr__ of <LTImage(img0) 270.000,720.000,336.000,780.000 (192, 169)>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nPrinted:\\n\\n5/30/2013\\n\\nTests\\nAPPEARANCE\\nPARTICLE SIZE\\nPARTICLE SIZE\\nBULK DENSITY\\nIDENTIFICATION\\nIDENTIFICATION 2\\nIDENTIFICATION 3\\nSPECIFIC ROTATION\\nSPECIFIC ROTATION\\nSPECIFIC ROTATION\\nLOSS ON DRYING\\nRESIDUE ON IGNITION\\nHEAVY METALS\\nLEAD\\nARSENIC\\nCADMIUM\\nLIMIT OF LUMIFLAVIN\\nRESIDUAL SOLVENTS <467>\\nASSAY (ON DRIED BASIS)\\nMICROBIOLOGICAL LIMITS\\nTOTAL PLATE COUNT\\nMOLD & YEAST\\nCOLIFORMS\\nE. COLI (MPN/G)\\nSALMONELLA (/25G)\\nPSEUDOMONAS\\nS. AUREUS\\nTAPPED DENSITY\\n\\n\"Sourcing & Supplying Quality Products Worldwide\"\\nTECHNICAL DATA SHEET\\nRIBOFLAVIN USP (VITAMIN B-2)   \\nAceto Product Code#:4612800\\n\\nAceto Corporation\\n4 Tri Harbor Court\\nPort Washington, NY 11050\\nPhone: (516) 627-6000\\nFax: (516) 627-6093\\nWebsite: www.aceto.com\\nTECHNICAL DATA SHEET\\nRIBOFLAVIN USP (VITAMIN B-2)   \\nAceto Product Code#:4612800\\nCAS#:83-88-5\\n\\nSpecification\\nORANGE YELLOW CRYSTALLINE PDR\\nNLT 90% THROUGH AN 100 MESH\\n100%  THROUGH AN 80 MESH\\nCa 250 - 300 G/L\\nPASS\\nPASS (JP)\\nPASS (JP)\\n-115\\xc2\\xb0 TO -135\\xc2\\xb0 (USP)\\n+56.5\\xc2\\xb0 - +59.5\\xc2\\xb0(FCC)\\n-142\\xc2\\xb0 TO -128\\xc2\\xb0  (JP)\\n1.5% MAX\\n0.3% MAX\\n10 PPM MAX\\n0.5 PPM MAX.\\n1.0 PPM MAX\\n1.0 PPM MAX\\n0.025 MAX AT 440NM\\nMETHOD IV\\n98.0% TO 102%\\n< 1000 CFU/GRAM\\n< 100 CFU/GRAM\\n< 10 CFU/GRAM\\nNEGATIVE\\nNEGATIVE\\nNEGATIVE\\nNEGATIVE\\nREPORT ONLY\\nLast Modified:\\n\\n01/11/2013\\n']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pages(file_name5, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PDFMiner HTML Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\\n</head><body>\\n<span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:792px;\"></span>\\n<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>\\n<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:259px; top:120px; width:86px; height:31px;\"><span style=\"font-family: AAAAAA+Arial; font-size:14px\">Aceto Corporation\\n<br></span><span style=\"font-family: AAAAAA+Arial; font-size:13px\">4 Tri Harbor Court\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:241px; top:151px; width:122px; height:13px;\"><span style=\"font-family: AAAAAA+Arial; font-size:13px\">Port Washington, NY 11050\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:252px; top:164px; width:101px; height:25px;\"><span style=\"font-family: AAAAAA+Arial; font-size:13px\">Phone: (516) 627-6000\\n<br>Fax: (516) 627-6093\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:247px; top:189px; width:110px; height:13px;\"><span style=\"font-family: AAAAAA+Arial; font-size:13px\">Website: www.aceto.com\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:204px; top:205px; width:198px; height:11px;\"><span style=\"font-family: AAAAAB+TimesNewRoman,BoldItalic; font-size:11px\">&quot;Sourcing &amp; Supplying Quality Products Worldwide&quot;\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:214px; top:224px; width:170px; height:39px;\"><span style=\"font-family: AAAAAC+TimesNewRoman,Italic; font-size:19px\">TECHNICAL DATA SHEET\\n<br></span><span style=\"font-family: AAAAAD+Arial,Bold; font-size:14px\">RIBOFLAVIN USP (VITAMIN B-2)   \\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:238px; top:266px; width:122px; height:11px;\"><span style=\"font-family: AAAAAA+Arial; font-size:11px\">Aceto Product Code#:4612800\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:271px; top:277px; width:56px; height:11px;\"><span style=\"font-family: AAAAAA+Arial; font-size:11px\">CAS#:83-88-5\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:108px; top:288px; width:111px; height:345px;\"><span style=\"font-family: AAAAAE+Arial,Italic; font-size:11px\">Tests\\n<br></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">APPEARANCE\\n<br>PARTICLE SIZE\\n<br></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">PARTICLE SIZE\\n<br>BULK DENSITY\\n<br>IDENTIFICATION\\n<br>IDENTIFICATION 2\\n<br>IDENTIFICATION 3\\n<br>SPECIFIC ROTATION\\n<br>SPECIFIC ROTATION\\n<br>SPECIFIC ROTATION\\n<br>LOSS ON DRYING\\n<br>RESIDUE ON IGNITION\\n<br>HEAVY METALS\\n<br>LEAD\\n<br>ARSENIC\\n<br>CADMIUM\\n<br>LIMIT OF LUMIFLAVIN\\n<br>RESIDUAL SOLVENTS &lt;467&gt;\\n<br>ASSAY (ON DRIED BASIS)\\n<br>MICROBIOLOGICAL LIMITS\\n<br>TOTAL PLATE COUNT\\n<br>MOLD &amp; YEAST\\n<br>COLIFORMS\\n<br>E. COLI (MPN/G)\\n<br>SALMONELLA (/25G)\\n<br>PSEUDOMONAS\\n<br>S. AUREUS\\n<br>TAPPED DENSITY\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:384px; top:288px; width:148px; height:237px;\"><span style=\"font-family: AAAAAE+Arial,Italic; font-size:11px\">Specification\\n<br></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">ORANGE YELLOW CRYSTALLINE PDR\\n<br>NLT 90% THROUGH AN 100 MESH\\n<br></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">100%  THROUGH AN 80 MESH\\n<br>Ca 250 - 300 G/L\\n<br>PASS\\n<br>PASS (JP)\\n<br>PASS (JP)\\n<br>-115\\xc2\\xb0 TO -135\\xc2\\xb0 (USP)\\n<br>+56.5\\xc2\\xb0 - +59.5\\xc2\\xb0(FCC)\\n<br>-142\\xc2\\xb0 TO -128\\xc2\\xb0  (JP)\\n<br>1.5% MAX\\n<br>0.3% MAX\\n<br>10 PPM MAX\\n<br>0.5 PPM MAX.\\n<br>1.0 PPM MAX\\n<br>1.0 PPM MAX\\n<br>0.025 MAX AT 440NM\\n<br>METHOD IV\\n<br>98.0% TO 102%\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:384px; top:540px; width:70px; height:94px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">&lt; 1000 CFU/GRAM\\n<br>&lt; 100 CFU/GRAM\\n<br>&lt; 10 CFU/GRAM\\n<br>NEGATIVE\\n<br>NEGATIVE\\n<br>NEGATIVE\\n<br>NEGATIVE\\n<br>REPORT ONLY\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:12px; top:807px; width:27px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">Printed:\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:808px; width:36px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">5/30/2013\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:435px; top:807px; width:50px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">Last Modified:\\n<br></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:504px; top:808px; width:40px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">01/11/2013\\n<br></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:270px; top:62px; width:66px; height:60px;\"></div><span style=\"position:absolute; border: black 1px solid; left:217px; top:241px; width:164px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:108px; top:299px; width:21px; height:0px;\"></span>\\n<span style=\"position:absolute; border: black 1px solid; left:384px; top:299px; width:50px; height:0px;\"></span>\\n<div style=\"position:absolute; top:0px;\">Page: <a href=\"#1\">1</a></div>\\n</body></html>\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pdf_to_html(file_name5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "PDFMiner is quirky to install but once set up, it does extract the table of contents and the text from a PDF. The text is raw and requires further regexing to extract the required information.\n",
    "\n",
    "Have not experimented with PDFMiner's layout parsing capability -- need to explore that next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TabulaPy for Extracting Tables from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Install TabulaPy (https://github.com/chezou/tabula-py)\n",
    "from tabula import read_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_pdf(file_name5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works well if the tables are explicit in the PDF -- not so well otherwise. Even when tables are clear in the PDF, only some of the tables get pulled out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try pdftables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdftables requires poppler and cairo -- packages that I haven't been able to install correctly on my system yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileobj = open(file_name, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pdftables.pdf_document",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6430c0a69dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdftables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf_document\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDFDocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_fileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pdftables.pdf_document"
     ]
    }
   ],
   "source": [
    "from pdftables.pdf_document import PDFDocument\n",
    "doc = PDFDocument.from_fileobj(fileobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extract Tables Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From http://srome.github.io/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas/\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "    \n",
    "class HTMLTableParser:\n",
    "       \n",
    "        def parse_url(self, url):\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            return [(table['id'],self.parse_html_table(table))\\\n",
    "                    for table in soup.find_all('table')]  \n",
    "    \n",
    "        def parse_html_table(self, table):\n",
    "            n_columns = 0\n",
    "            n_rows=0\n",
    "            column_names = []\n",
    "    \n",
    "            # Find number of rows and columns\n",
    "            # we also find the column titles if we can\n",
    "            for row in table.find_all('tr'):\n",
    "                \n",
    "                # Determine the number of rows in the table\n",
    "                td_tags = row.find_all('td')\n",
    "                if len(td_tags) > 0:\n",
    "                    n_rows+=1\n",
    "                    if n_columns == 0:\n",
    "                        # Set the number of columns for our table\n",
    "                        n_columns = len(td_tags)\n",
    "                        \n",
    "                # Handle column names if we find them\n",
    "                th_tags = row.find_all('th') \n",
    "                if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                    for th in th_tags:\n",
    "                        column_names.append(th.get_text())\n",
    "    \n",
    "            # Safeguard on Column Titles\n",
    "            if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "                raise Exception(\"Column titles do not match the number of columns\")\n",
    "    \n",
    "            columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "            df = pd.DataFrame(columns = columns,\n",
    "                              index= range(0,n_rows))\n",
    "            row_marker = 0\n",
    "            for row in table.find_all('tr'):\n",
    "                column_marker = 0\n",
    "                columns = row.find_all('td')\n",
    "                for column in columns:\n",
    "                    df.iat[row_marker,column_marker] = column.get_text()\n",
    "                    column_marker += 1\n",
    "                if len(columns) > 0:\n",
    "                    row_marker += 1\n",
    "                    \n",
    "            # Convert to float if possible\n",
    "            for col in df:\n",
    "                try:\n",
    "                    df[col] = df[col].astype(float)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       "</head><body>\n",
       "<span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:792px;\"></span>\n",
       "<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>\n",
       "<div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:259px; top:120px; width:86px; height:31px;\"><span style=\"font-family: AAAAAA+Arial; font-size:14px\">Aceto Corporation\n",
       "<br/></span><span style=\"font-family: AAAAAA+Arial; font-size:13px\">4 Tri Harbor Court\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:241px; top:151px; width:122px; height:13px;\"><span style=\"font-family: AAAAAA+Arial; font-size:13px\">Port Washington, NY 11050\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:252px; top:164px; width:101px; height:25px;\"><span style=\"font-family: AAAAAA+Arial; font-size:13px\">Phone: (516) 627-6000\n",
       "<br/>Fax: (516) 627-6093\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:247px; top:189px; width:110px; height:13px;\"><span style=\"font-family: AAAAAA+Arial; font-size:13px\">Website: www.aceto.com\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:204px; top:205px; width:198px; height:11px;\"><span style=\"font-family: AAAAAB+TimesNewRoman,BoldItalic; font-size:11px\">\"Sourcing &amp; Supplying Quality Products Worldwide\"\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:214px; top:224px; width:170px; height:39px;\"><span style=\"font-family: AAAAAC+TimesNewRoman,Italic; font-size:19px\">TECHNICAL DATA SHEET\n",
       "<br/></span><span style=\"font-family: AAAAAD+Arial,Bold; font-size:14px\">RIBOFLAVIN USP (VITAMIN B-2)   \n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:238px; top:266px; width:122px; height:11px;\"><span style=\"font-family: AAAAAA+Arial; font-size:11px\">Aceto Product Code#:4612800\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:271px; top:277px; width:56px; height:11px;\"><span style=\"font-family: AAAAAA+Arial; font-size:11px\">CAS#:83-88-5\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:108px; top:288px; width:111px; height:345px;\"><span style=\"font-family: AAAAAE+Arial,Italic; font-size:11px\">Tests\n",
       "<br/></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">APPEARANCE\n",
       "<br/>PARTICLE SIZE\n",
       "<br/></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">PARTICLE SIZE\n",
       "<br/>BULK DENSITY\n",
       "<br/>IDENTIFICATION\n",
       "<br/>IDENTIFICATION 2\n",
       "<br/>IDENTIFICATION 3\n",
       "<br/>SPECIFIC ROTATION\n",
       "<br/>SPECIFIC ROTATION\n",
       "<br/>SPECIFIC ROTATION\n",
       "<br/>LOSS ON DRYING\n",
       "<br/>RESIDUE ON IGNITION\n",
       "<br/>HEAVY METALS\n",
       "<br/>LEAD\n",
       "<br/>ARSENIC\n",
       "<br/>CADMIUM\n",
       "<br/>LIMIT OF LUMIFLAVIN\n",
       "<br/>RESIDUAL SOLVENTS &lt;467&gt;\n",
       "<br/>ASSAY (ON DRIED BASIS)\n",
       "<br/>MICROBIOLOGICAL LIMITS\n",
       "<br/>TOTAL PLATE COUNT\n",
       "<br/>MOLD &amp; YEAST\n",
       "<br/>COLIFORMS\n",
       "<br/>E. COLI (MPN/G)\n",
       "<br/>SALMONELLA (/25G)\n",
       "<br/>PSEUDOMONAS\n",
       "<br/>S. AUREUS\n",
       "<br/>TAPPED DENSITY\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:384px; top:288px; width:148px; height:237px;\"><span style=\"font-family: AAAAAE+Arial,Italic; font-size:11px\">Specification\n",
       "<br/></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">ORANGE YELLOW CRYSTALLINE PDR\n",
       "<br/>NLT 90% THROUGH AN 100 MESH\n",
       "<br/></span><span style=\"font-family: AAAAAA+Arial; font-size:10px\">100%  THROUGH AN 80 MESH\n",
       "<br/>Ca 250 - 300 G/L\n",
       "<br/>PASS\n",
       "<br/>PASS (JP)\n",
       "<br/>PASS (JP)\n",
       "<br/>-115° TO -135° (USP)\n",
       "<br/>+56.5° - +59.5°(FCC)\n",
       "<br/>-142° TO -128°  (JP)\n",
       "<br/>1.5% MAX\n",
       "<br/>0.3% MAX\n",
       "<br/>10 PPM MAX\n",
       "<br/>0.5 PPM MAX.\n",
       "<br/>1.0 PPM MAX\n",
       "<br/>1.0 PPM MAX\n",
       "<br/>0.025 MAX AT 440NM\n",
       "<br/>METHOD IV\n",
       "<br/>98.0% TO 102%\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:384px; top:540px; width:70px; height:94px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">&lt; 1000 CFU/GRAM\n",
       "<br/>&lt; 100 CFU/GRAM\n",
       "<br/>&lt; 10 CFU/GRAM\n",
       "<br/>NEGATIVE\n",
       "<br/>NEGATIVE\n",
       "<br/>NEGATIVE\n",
       "<br/>NEGATIVE\n",
       "<br/>REPORT ONLY\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:12px; top:807px; width:27px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">Printed:\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:54px; top:808px; width:36px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">5/30/2013\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:435px; top:807px; width:50px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">Last Modified:\n",
       "<br/></span></div><div style=\"position:absolute; border: textbox 1px solid; writing-mode:lr-tb; left:504px; top:808px; width:40px; height:10px;\"><span style=\"font-family: AAAAAA+Arial; font-size:10px\">01/11/2013\n",
       "<br/></span></div><div style=\"position:absolute; border: figure 1px solid; writing-mode:False; left:270px; top:62px; width:66px; height:60px;\"></div><span style=\"position:absolute; border: black 1px solid; left:217px; top:241px; width:164px; height:0px;\"></span>\n",
       "<span style=\"position:absolute; border: black 1px solid; left:108px; top:299px; width:21px; height:0px;\"></span>\n",
       "<span style=\"position:absolute; border: black 1px solid; left:384px; top:299px; width:50px; height:0px;\"></span>\n",
       "<div style=\"position:absolute; top:0px;\">Page: <a href=\"#1\">1</a></div>\n",
       "</body></html>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(convert_pdf_to_html(file_name5), 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-b3903ac14a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tables = soup.find_all('table')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pbs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7ae1377705dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcStringIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpbs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdftotext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pbs"
     ]
    }
   ],
   "source": [
    "# From https://github.com/liberit/scraptils/blob/master/scraptils/tools/pdf2csv.py\n",
    "\n",
    "# converts a pdf into a csv file\n",
    "\n",
    "#from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.layout import LAParams, LTRect\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from itertools import islice\n",
    "import sys, csv, cStringIO, codecs\n",
    "from pbs import pdftotext\n",
    "\n",
    "class UnicodeWriter:\n",
    "    \"\"\"\n",
    "    A CSV writer which will write rows to CSV file \"f\",\n",
    "    which is encoded in the given encoding.\n",
    "    src: http://docs.python.org/library/csv.html#writer-objects\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, f, dialect=csv.excel, encoding=\"utf-8\", **kwds):\n",
    "        # Redirect output to a queue\n",
    "        self.queue = cStringIO.StringIO()\n",
    "        self.writer = csv.writer(self.queue, dialect=dialect, **kwds)\n",
    "        self.stream = f\n",
    "        self.encoder = codecs.getincrementalencoder(encoding)()\n",
    "\n",
    "    def writerow(self, row):\n",
    "        self.writer.writerow([s.encode(\"utf-8\") if isinstance(s, basestring) else s\n",
    "                              for s in row])\n",
    "        # Fetch UTF-8 output from the queue ...\n",
    "        data = self.queue.getvalue()\n",
    "        data = data.decode(\"utf-8\")\n",
    "        # ... and reencode it into the target encoding\n",
    "        data = self.encoder.encode(data)\n",
    "        # write to the target stream\n",
    "        self.stream.write(data)\n",
    "        # empty queue\n",
    "        self.queue.truncate(0)\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "def pdf2csv(pdf):\n",
    "    fp = open(pdf, 'rb')\n",
    "    parser = PDFParser(fp)\n",
    "    doc = PDFDocument()\n",
    "    parser.set_document(doc)\n",
    "    doc.set_parser(parser)\n",
    "    # Supply the password for initialization.\n",
    "    # (If no password is set, give an empty string.)\n",
    "    doc.initialize('')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    # Set parameters for analysis.\n",
    "    laparams = LAParams()\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "    writer = UnicodeWriter(sys.stdout)\n",
    "    for pageno, page in enumerate(doc.get_pages()):\n",
    "        interpreter.process_page(page)\n",
    "        layout = device.get_result()\n",
    "        hlines=[]\n",
    "        vlines=[]\n",
    "        for i in layout:\n",
    "            if not type(i) == LTRect: continue\n",
    "            hlines.append(int(i.x0))\n",
    "            hlines.append(int(i.x1))\n",
    "            vlines.append(int(layout.height - i.y0))\n",
    "            vlines.append(int(layout.height - i.y1))\n",
    "        hlines=filterclose(sorted(set(hlines)))\n",
    "        vlines=filterclose(sorted(set(vlines)))\n",
    "        i=0\n",
    "        while(i<len(vlines)-1):\n",
    "            if not vlines[i+1]-vlines[i]>10:\n",
    "                i=i+1\n",
    "                continue\n",
    "            j=0\n",
    "            row=[]\n",
    "            while(j<len(hlines)-1):\n",
    "                if not hlines[j+1]-hlines[j]>10:\n",
    "                    j=j+1\n",
    "                    continue\n",
    "                row.append(' '.join(get_region(pdf,\n",
    "                                               pageno+1,\n",
    "                                               hlines[j]+1,\n",
    "                                               vlines[i],\n",
    "                                               hlines[j+1]-1,\n",
    "                                               vlines[i+1]).split()))\n",
    "                j=j+1\n",
    "            writer.writerow(row)\n",
    "            i=i+1\n",
    "    fp.close()\n",
    "\n",
    "def filterclose(lst):\n",
    "    tmp=[lst[0]]\n",
    "    for elem in islice(lst, 1, None):\n",
    "        if elem - 2 > tmp[-1]:\n",
    "            tmp.append(elem)\n",
    "    return tmp\n",
    "\n",
    "def get_region(pdf, page, x1,y1,x2,y2):\n",
    "    # this is an extremely ugly hack. should be reimplemented with\n",
    "    # some poppler like lib, which itself only supports getting\n",
    "    # \"selected\" text, having some different logic than the\n",
    "    # simple one used in pdftotext\n",
    "    return pdftotext('-nopgbrk',\n",
    "                     '-f', page,\n",
    "                     '-l', page,\n",
    "                     '-x', x1,\n",
    "                     '-y', y1,\n",
    "                     '-H', abs(y2-y1),\n",
    "                     '-W', abs(x2-x1),\n",
    "                     pdf,\n",
    "                     '-'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'catalog'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-0630cfb07fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPDFPage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# receive the LTPage object for the page.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jsubapple/anaconda/lib/python2.7/site-packages/pdfminer/pdfpage.pyc\u001b[0m in \u001b[0;36mcreate_pages\u001b[0;34m(klass, document, debug)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'Pages'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobjid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'catalog'"
     ]
    }
   ],
   "source": [
    "for page in PDFPage.create_pages(file_name1):\n",
    "    interpreter.process_page(page)\n",
    "    # receive the LTPage object for the page.\n",
    "    layout = device.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-14f9b4a5c6c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlt_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layout' is not defined"
     ]
    }
   ],
   "source": [
    "for lt_obj in layout:\n",
    "    print(lt_obj.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTTextBoxHorizontal\n",
      "(264.6, 689.9617999999999, 351.23425, 721.27925)\n",
      "Aceto Corporation\n",
      "4 Tri Harbor Court\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(246.8, 677.2618, 368.89075, 690.37215)\n",
      "Port Washington, NY 11050\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(257.2, 651.8618, 358.4974, 677.67215)\n",
      "Phone: (516) 627-6000\n",
      "Fax: (516) 627-6093\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(252.6, 639.1618, 363.16625, 652.27215)\n",
      "Website: www.aceto.com\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(209.05, 625.0776, 407.10169999999994, 636.9947)\n",
      "\"Sourcing & Supplying Quality Products Worldwide\"\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(222.6, 578.824, 387.1855, 617.9973)\n",
      "TECHNICAL DATA SHEET\n",
      "RIBOFLAVIN (VITAMIN B-2)   \n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(243.6, 563.3526, 365.9912500000001, 575.26505)\n",
      "Aceto Product Code#:4612801\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(276.6, 552.1526, 333.3072, 564.0650499999999)\n",
      "CAS#:83-88-5\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(113.05, 279.13280000000003, 242.69050000000007, 553.04345)\n",
      "Tests\n",
      "APPEARANCE\n",
      "IDENTIFICATION\n",
      "SPECIFIC ROTATION, °\n",
      "LOSS ON DRYING, %\n",
      "RESIDUE ON IGNITION, %\n",
      "LUMIFLAVIN (440nm Absorbances)\n",
      "ASSAY (on dried basis) %\n",
      "PARTICLE SIZE\n",
      "PARTICLE SIZE\n",
      "BULK DENSITY\n",
      "TOTAL PLATE COUNT\n",
      "MOLD & YEAST\n",
      "COLIFORMS\n",
      "E. COLI\n",
      "SALMONELLA (/25G)\n",
      "PSEUDOMONAS AERUGINOSA\n",
      "STAPHYLOCOCCUS AUREUS\n",
      "HEAVY METALS\n",
      "LEAD\n",
      "ARSENIC\n",
      "CADMIUM\n",
      "RESIDUAL SOLVENTS\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(389.05, 279.13280000000003, 505.6252, 553.04345)\n",
      "Specification\n",
      "Yellow/Orange Ylw Crystal Pwdr\n",
      "CONFORM\n",
      "-115 ~ -135\n",
      "NMT 1.5\n",
      " NMT 0.3\n",
      "NMT 0.025\n",
      "98.0 ~ 102.0\n",
      "100% THRU  8O MESH\n",
      "NLT 90% THRU  100 MESH\n",
      "220 - 310 g/l\n",
      "NMT 1000 cfu/g\n",
      "NMT 100 cfu/g\n",
      "NMT 10 cfu/g\n",
      "NEGATIVE\n",
      "NEGATIVE\n",
      "NEGATIVE\n",
      "NEGATIVE\n",
      "NMT 10 ppm\n",
      "NMT 1.0 ppm\n",
      "NMT 1.0 ppm\n",
      "NMT 1.0 ppm\n",
      "Only water used in mfg process\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(17.05000000000001, 23.232800000000047, 44.962600000000016, 34.01390000000004)\n",
      "Printed:\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(59.05000000000001, 23.182800000000093, 95.07880000000002, 33.96390000000009)\n",
      "9/25/2013\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(440.85, 23.232800000000047, 491.27250000000004, 34.01390000000004)\n",
      "Last Modified:\n",
      "\n",
      "LTTextBoxHorizontal\n",
      "(509.05, 23.182800000000093, 549.5824, 33.96390000000009)\n",
      "09/19/2012\n",
      "\n",
      "LTFigure\n",
      "(275.05, 720.0, 341.05, 780.0)\n",
      "LTImage\n",
      "(275.05, 720.0, 341.05, 780.0)\n",
      "LTRect\n",
      "(222.6, 599.6, 387.45, 600.3)\n",
      "LTRect\n",
      "(113.05, 541.5, 135.0, 542.15)\n",
      "LTRect\n",
      "(389.05, 541.5, 440.0, 542.15)\n"
     ]
    }
   ],
   "source": [
    "# Using the parsed object tree from PDFMiner\n",
    "# From Matt Swain\n",
    "# http://stackoverflow.com/questions/25248140/how-does-one-obtain-the-location-of-text-in-a-pdf-with-pdfminer\n",
    "\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine, LTFigure\n",
    "\n",
    "\n",
    "def parse_layout(layout):\n",
    "    \"\"\"Function to recursively parse the layout tree.\"\"\"\n",
    "    for lt_obj in layout:\n",
    "        print(lt_obj.__class__.__name__)\n",
    "        print(lt_obj.bbox)\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            print(lt_obj.get_text())\n",
    "        elif isinstance(lt_obj, LTFigure):\n",
    "            parse_layout(lt_obj)  # Recursive\n",
    "\n",
    "\n",
    "fp = open(file_name2, 'rb')\n",
    "parser = PDFParser(fp)\n",
    "doc = PDFDocument(parser)\n",
    "\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "for page in PDFPage.create_pages(doc):\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    parse_layout(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
